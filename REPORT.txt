MOTIVACIJA:
Biclustering najprej po eni dimenziji in potem po drugi se slabo obnese pri matrikah, ki so podobne šahovnici. Že izredno majhne razlike pri vhodnih podatkih lahko precej spremenijo kvaliteto rešitev.


POVPREČJE PRI BRUTE FORCU (biclustering-staro):
- večje dimenzije imajo slabše razmerje (1D vs 2D)
- pri cost functionu Multiply8 skoraj ni razlike za večje dimenzije (1.0, 0.99, 0.99) pri dimenzijah (3*3, 4*4, 5*5)
- pri cost functionu Squared8 večje razlike za večje dimenzije (1.02, 1.05, 1.08) pri dimenzijah (3*3, 4*4, 5*5)
- pri cost functionu Variance22 večje razlike za večje dimenzije (1.02, 1.05, 1.06) pri dimenzijah (3*3, 4*4, 5*5)

- za večje dimenzije 6*6 in več, potrebujemo paralelizem in več časa
- za končno rešitev so kvadrati na diagonali boljši kot čista diagonala
- že zelo majhne spremembe v vhodnih podatkih lahko zelo spremenijo razmerje med 1D in 2D (celo spremembe do 10^⁻3)

---------------------------------------------------------------------------

TRIKOTNIŠKA ENAKOST ZA VARIANCO 2*2 NE VELJA (PROTIPRIMER):
0 | 1           0 | 0.5 | 1
0 | 1           0 | 0.5 | 1
cost = 1        cost = 0.5

---------------------------------------------------------------------------

PRIČAKOVANA VREDNOST MINIMUMA n VREDNOSTI, PORAZDELJENIH UNIFORMNO:
- 1 / (n + 1)
- izračunal sam, enako kot vir:
https://math.stackexchange.com/questions/786392/expectation-of-minimum-of-n-i-i-d-uniform-random-variables 

---------------------------------------------------------------------------

PRIČAKOVANA VREDNOST MINIMUMA n VREDNOSTI, BETA DISTRIBUTION:
- porazdelitev sem dobil z Mathematico (FindDistribution) na 100000 naključno generiranih primerih. Primere sem generiral kot matrike velikosti 2 * 2, z vnosi med 0 in 1, porazdelejino uniformno

- najboljši distribuciji glede na Mathematico(FindDistribution):
 - BetaDistribution[a = 1.50601, b = 4.71801]
 - WeibullDistribution[1.55815, 0.26859]

- CDF minimuma n vnosov, CDF spremenljivke X = F(x): 1 - (1 - F(x))^n
- kot v viru:
https://stats.stackexchange.com/questions/220/how-is-the-minimum-of-a-set-of-random-variables-distributed?fbclid=IwAR1dCpEbwRxVns4s9WONNVBbmLxhWAxikxdBYiCtiKYwcAwKDzpmkaIVCRc

- da dobimo pričakovano vrednost rabimo moramo izračunati integral med 0 in 1: x * PDF(x)

- PDF je odvod CDF: n * (1 - F(x)) ^ (n - 1) * F'(x), kjer je F'(x) PDF spremenljivke X

- beta disibucija - CDF in PDF:
https://reference.wolfram.com/language/ref/BetaDistribution.html

- pričakovane vrednosti za spremenljivko se na žalost zaradi kompleksnosti ne da izračunati analitično, zato moramo uporabiti aproksimacijo

- rezultati za manjša števila niso čisto enaki kot pri eksperimetnu, ampak za večja števila pa začnejo dobro konvergirati
---------------------------------------------------------------------------
POTREBNI BOLJ EKSAKTNI DOKAZI IN OPISI ALGORITMOV!!!!!!!!!!


LOWER BOUND 1 DIMENZIJA:
- lower_bound_1_closest:

- lower_bound_2_closest:

- lower_bound_spanning_tree:


ALGORITMI 1 DIMENZIJA:
- all_permutations:

- random_permutations:

- spanning tree:

- random_greedy_path_two_ends:


---------------------------------------------------------------------------

RAZNE UGOTOVITE:
- lower_bound_2_closest daje boljše oceno spodnje meje kot lower_bound_spanning_tree

- lower_bound_spanning_tree daje boljšo oceno spodnje meje kot lower_bound_1_closest

- spanning_tree algoritem deluje boljše kot random_greedy_path_two_ends. Razlika je precej majhna, vendar pri večjih primerih je spanning tree konstantno boljši. Pri majhnih primerih se zgodi tudi, da je random_greedy_path_two_ends včasih boljši (npr. pri velikostih do 10)

- glavni problem pri pospešitvah algoritmov je računanje matrike razdalj, ki deluje v O(n^2 * m)

- trenutna implemtacija 2-opt (prva, naivna) dela podobno dobro kot spanning tree